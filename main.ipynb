{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ddd854c-bf4b-48f2-84b0-b01990c2a892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (42000, 785)\n",
      "test: (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('digit-recognizer/train.csv')\n",
    "test = pd.read_csv('digit-recognizer/test.csv')\n",
    "\n",
    "print('train:', train.shape)\n",
    "print('test:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d22fd4-4147-4868-a1a6-2bd3e7e225f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d73e59-fbf5-4d44-be77-d7dde253500d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794e1b18-520c-4e39-8cc3-11b7e7684a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.labels = dataframe.iloc[:, 0].values\n",
    "        self.images = dataframe.iloc[:, 1:].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index].reshape(28, 28).astype(np.uint8)\n",
    "        label = self.labels[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.images = dataframe.values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index].reshape(28, 28).astype(np.uint8)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "train_mean = train.drop('label', axis=1).values.mean()/255\n",
    "train_std = train.drop('label', axis=1).values.std()/255\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.RandomAffine(degrees=5, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.1, p=0.25),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_mean, train_std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_mean, train_std)\n",
    "])\n",
    "\n",
    "train_data = TrainDataset(train, transform=train_transform)\n",
    "test_data = TestDataset(test, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fb64089-1c80-4be9-98c7-a354170c182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(30):  \n",
    "    plt.subplot(3, 10, i+1)\n",
    "    plt.imshow(train_data.images[i].reshape((28, 28)), cmap=plt.cm.binary)\n",
    "    plt.title(train_data.labels[i])\n",
    "    plt.axis('off')\n",
    "plt.subplots_adjust(wspace=-0.1, hspace=-0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd56c14b-786f-4911-b8ed-2e27de5fc1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128, 10),\n",
    "        )   \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5366021d-cfc4-4478-8bd0-527b8b9739de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58ae2420-4678-4c1d-a5e6-57e1960f0d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 | epoch 1 | 0.087 | 0.016 | 0.546 | network improved\n",
      "fold 1 | epoch 2 | 0.061 | 0.010 | 0.740 | network improved\n",
      "fold 1 | epoch 3 | 0.045 | 0.007 | 0.812 | network improved\n",
      "fold 1 | epoch 4 | 0.035 | 0.005 | 0.859 | network improved\n",
      "fold 1 | epoch 5 | 0.028 | 0.004 | 0.891 | network improved\n",
      "fold 1 | epoch 6 | 0.024 | 0.004 | 0.907 | network improved\n",
      "fold 1 | epoch 7 | 0.021 | 0.003 | 0.921 | network improved\n",
      "fold 1 | epoch 8 | 0.019 | 0.003 | 0.929 | network improved\n",
      "fold 1 | epoch 9 | 0.017 | 0.002 | 0.933 | network improved\n",
      "fold 1 | epoch 10 | 0.016 | 0.002 | 0.939 | network improved\n",
      "fold 1 | epoch 11 | 0.015 | 0.002 | 0.948 | network improved\n",
      "fold 1 | epoch 12 | 0.014 | 0.002 | 0.948 | network improved\n",
      "fold 1 | epoch 13 | 0.013 | 0.002 | 0.951 | network improved\n",
      "fold 1 | epoch 14 | 0.012 | 0.002 | 0.953 | network improved\n",
      "fold 1 | epoch 15 | 0.012 | 0.002 | 0.959 | network improved\n",
      "fold 1 | epoch 16 | 0.011 | 0.001 | 0.960 | network improved\n",
      "fold 1 | epoch 17 | 0.011 | 0.001 | 0.962 | network improved\n",
      "fold 1 | epoch 18 | 0.010 | 0.001 | 0.961\n",
      "fold 1 | epoch 19 | 0.010 | 0.001 | 0.965 | network improved\n",
      "fold 1 | epoch 20 | 0.010 | 0.001 | 0.966 | network improved\n",
      "fold 1 | epoch 21 | 0.009 | 0.001 | 0.965 | network improved\n",
      "fold 1 | epoch 22 | 0.009 | 0.001 | 0.968 | network improved\n",
      "fold 1 | epoch 23 | 0.009 | 0.001 | 0.969 | network improved\n",
      "fold 1 | epoch 24 | 0.009 | 0.001 | 0.969 | network improved\n",
      "fold 1 | epoch 25 | 0.008 | 0.001 | 0.969 | network improved\n",
      "fold 1 | epoch 26 | 0.008 | 0.001 | 0.969 | network improved\n",
      "fold 1 | epoch 27 | 0.008 | 0.001 | 0.969 | network improved\n",
      "fold 1 | epoch 28 | 0.008 | 0.001 | 0.969\n",
      "fold 1 | epoch 29 | 0.008 | 0.001 | 0.970 | network improved\n",
      "fold 1 | epoch 30 | 0.008 | 0.001 | 0.972 | network improved\n",
      "fold 1 | epoch 31 | 0.008 | 0.001 | 0.972\n",
      "fold 1 | epoch 32 | 0.007 | 0.001 | 0.974 | network improved\n",
      "fold 1 | epoch 33 | 0.007 | 0.001 | 0.975\n",
      "fold 1 | epoch 34 | 0.007 | 0.001 | 0.974 | network improved\n",
      "fold 1 | epoch 35 | 0.007 | 0.001 | 0.976\n",
      "fold 1 | epoch 36 | 0.007 | 0.001 | 0.974\n",
      "fold 1 | epoch 37 | 0.007 | 0.001 | 0.975 | network improved\n",
      "fold 1 | epoch 38 | 0.007 | 0.001 | 0.974\n",
      "fold 1 | epoch 39 | 0.007 | 0.001 | 0.976 | network improved\n",
      "fold 1 | epoch 40 | 0.006 | 0.001 | 0.976\n",
      "fold 1 | epoch 41 | 0.006 | 0.001 | 0.975\n",
      "fold 1 | epoch 42 | 0.006 | 0.001 | 0.978\n",
      "fold 1 | epoch 43 | 0.006 | 0.001 | 0.976\n",
      "fold 1 | epoch 44 | 0.006 | 0.001 | 0.979 | network improved\n",
      "fold 1 | epoch 45 | 0.006 | 0.001 | 0.976\n",
      "fold 1 | epoch 46 | 0.006 | 0.001 | 0.977\n",
      "fold 1 | epoch 47 | 0.006 | 0.001 | 0.979 | network improved\n",
      "fold 1 | epoch 48 | 0.006 | 0.001 | 0.975\n",
      "fold 1 | epoch 49 | 0.006 | 0.001 | 0.979 | network improved\n",
      "fold 1 | epoch 50 | 0.006 | 0.001 | 0.981\n",
      "fold 1 | epoch 51 | 0.006 | 0.001 | 0.980\n",
      "fold 1 | epoch 52 | 0.006 | 0.001 | 0.978 | network improved\n",
      "fold 1 | epoch 53 | 0.005 | 0.001 | 0.978 | network improved\n",
      "fold 1 | epoch 54 | 0.005 | 0.001 | 0.979\n",
      "fold 1 | epoch 55 | 0.005 | 0.001 | 0.981\n",
      "fold 1 | epoch 56 | 0.005 | 0.001 | 0.981\n",
      "fold 1 | epoch 57 | 0.005 | 0.001 | 0.981 | network improved\n",
      "fold 1 | epoch 58 | 0.005 | 0.001 | 0.981\n",
      "fold 1 | epoch 59 | 0.005 | 0.001 | 0.980\n",
      "fold 1 | epoch 60 | 0.005 | 0.001 | 0.980\n",
      "fold 1 | epoch 61 | 0.005 | 0.001 | 0.980\n",
      "fold 1 | epoch 62 | 0.005 | 0.001 | 0.983 | network improved\n",
      "fold 1 | epoch 63 | 0.005 | 0.001 | 0.981\n",
      "fold 1 | epoch 64 | 0.005 | 0.001 | 0.982\n",
      "fold 1 | epoch 65 | 0.005 | 0.001 | 0.983 | network improved\n",
      "fold 1 | epoch 66 | 0.005 | 0.001 | 0.983\n",
      "fold 1 | epoch 67 | 0.005 | 0.001 | 0.981\n",
      "fold 1 | epoch 68 | 0.005 | 0.001 | 0.982 | network improved\n",
      "fold 1 | epoch 69 | 0.005 | 0.001 | 0.983 | network improved\n",
      "fold 1 | epoch 70 | 0.005 | 0.001 | 0.981\n",
      "fold 1 | epoch 71 | 0.005 | 0.001 | 0.982 | network improved\n",
      "fold 1 | epoch 72 | 0.005 | 0.001 | 0.982\n",
      "fold 1 | epoch 73 | 0.005 | 0.001 | 0.984 | network improved\n",
      "fold 1 | epoch 74 | 0.005 | 0.001 | 0.983\n",
      "fold 1 | epoch 75 | 0.005 | 0.001 | 0.983\n",
      "fold 1 | epoch 76 | 0.004 | 0.001 | 0.985\n",
      "fold 1 | epoch 77 | 0.005 | 0.001 | 0.981\n",
      "fold 1 | epoch 78 | 0.004 | 0.001 | 0.985 | network improved\n",
      "fold 1 | epoch 79 | 0.004 | 0.001 | 0.982\n",
      "fold 1 | epoch 80 | 0.004 | 0.001 | 0.982\n",
      "fold 1 | epoch 81 | 0.004 | 0.001 | 0.983 | network improved\n",
      "fold 1 | epoch 82 | 0.004 | 0.001 | 0.982\n",
      "fold 1 | epoch 83 | 0.004 | 0.001 | 0.982\n",
      "fold 1 | epoch 84 | 0.004 | 0.001 | 0.984\n",
      "fold 1 | epoch 85 | 0.004 | 0.001 | 0.984 | network improved\n",
      "fold 1 | epoch 86 | 0.004 | 0.001 | 0.985 | network improved\n",
      "fold 1 | epoch 87 | 0.004 | 0.001 | 0.985\n",
      "fold 1 | epoch 88 | 0.004 | 0.001 | 0.983\n",
      "fold 1 | epoch 89 | 0.004 | 0.001 | 0.983\n",
      "fold 1 | epoch 90 | 0.004 | 0.001 | 0.985\n",
      "fold 1 | epoch 91 | 0.004 | 0.001 | 0.983\n",
      "fold 1 | epoch 92 | 0.004 | 0.001 | 0.982\n",
      "fold 1 | epoch 93 | 0.004 | 0.001 | 0.985 | network improved\n",
      "fold 1 | epoch 94 | 0.004 | 0.001 | 0.985 | network improved\n",
      "fold 1 | epoch 95 | 0.004 | 0.001 | 0.985\n",
      "fold 1 | epoch 96 | 0.004 | 0.001 | 0.985\n",
      "fold 1 | epoch 97 | 0.004 | 0.000 | 0.986 | network improved\n",
      "fold 1 | epoch 98 | 0.004 | 0.001 | 0.985\n",
      "fold 1 | epoch 99 | 0.004 | 0.001 | 0.985\n",
      "fold 1 | epoch 100 | 0.004 | 0.001 | 0.983\n",
      "fold 1 | epoch 101 | 0.004 | 0.001 | 0.985\n",
      "fold 1 | epoch 102 | 0.004 | 0.001 | 0.985\n",
      "fold 1 | epoch 103 | 0.004 | 0.001 | 0.985\n",
      "fold 1 | epoch 104 | 0.004 | 0.001 | 0.984\n",
      "fold 1 | epoch 105 | 0.004 | 0.000 | 0.986 | network improved\n",
      "fold 1 | epoch 106 | 0.004 | 0.001 | 0.985\n",
      "fold 1 | epoch 107 | 0.004 | 0.000 | 0.987\n",
      "fold 1 | epoch 108 | 0.004 | 0.000 | 0.986\n",
      "fold 1 | epoch 109 | 0.004 | 0.000 | 0.986\n",
      "fold 1 | epoch 110 | 0.004 | 0.000 | 0.986\n",
      "fold 1 | epoch 111 | 0.004 | 0.001 | 0.986\n",
      "fold 1 | epoch 112 | 0.004 | 0.000 | 0.987\n",
      "fold 1 | epoch 113 | 0.004 | 0.000 | 0.987 | network improved\n",
      "fold 1 | epoch 114 | 0.004 | 0.000 | 0.986\n",
      "fold 1 | epoch 115 | 0.004 | 0.000 | 0.987\n",
      "fold 1 | epoch 116 | 0.004 | 0.000 | 0.986\n",
      "fold 1 | epoch 117 | 0.003 | 0.000 | 0.986\n",
      "fold 1 | epoch 118 | 0.004 | 0.000 | 0.985\n",
      "fold 1 | epoch 119 | 0.004 | 0.000 | 0.986\n",
      "fold 1 | epoch 120 | 0.004 | 0.000 | 0.988\n",
      "fold 1 | epoch 121 | 0.004 | 0.000 | 0.986\n",
      "fold 1 | epoch 122 | 0.004 | 0.000 | 0.987\n",
      "fold 1 | epoch 123 | 0.004 | 0.000 | 0.986\n",
      "fold 1 | epoch 124 | 0.004 | 0.000 | 0.988\n",
      "fold 1 | epoch 125 | 0.003 | 0.000 | 0.985\n",
      "fold 1 | epoch 126 | 0.004 | 0.000 | 0.986\n",
      "fold 1 | epoch 127 | 0.003 | 0.000 | 0.984\n",
      "fold 1 | epoch 128 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 129 | 0.003 | 0.000 | 0.986\n",
      "fold 1 | epoch 130 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 131 | 0.003 | 0.000 | 0.986\n",
      "fold 1 | epoch 132 | 0.003 | 0.000 | 0.985\n",
      "fold 1 | epoch 133 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 134 | 0.003 | 0.000 | 0.988 | network improved\n",
      "fold 1 | epoch 135 | 0.003 | 0.000 | 0.986\n",
      "fold 1 | epoch 136 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 137 | 0.003 | 0.000 | 0.986\n",
      "fold 1 | epoch 138 | 0.003 | 0.000 | 0.985\n",
      "fold 1 | epoch 139 | 0.003 | 0.000 | 0.986\n",
      "fold 1 | epoch 140 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 141 | 0.003 | 0.000 | 0.986\n",
      "fold 1 | epoch 142 | 0.003 | 0.000 | 0.986\n",
      "fold 1 | epoch 143 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 144 | 0.003 | 0.000 | 0.987 | network improved\n",
      "fold 1 | epoch 145 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 146 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 147 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 148 | 0.003 | 0.000 | 0.988 | network improved\n",
      "fold 1 | epoch 149 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 150 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 151 | 0.003 | 0.000 | 0.986\n",
      "fold 1 | epoch 152 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 153 | 0.003 | 0.000 | 0.986\n",
      "fold 1 | epoch 154 | 0.003 | 0.000 | 0.986\n",
      "fold 1 | epoch 155 | 0.003 | 0.000 | 0.989 | network improved\n",
      "fold 1 | epoch 156 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 157 | 0.003 | 0.000 | 0.990\n",
      "fold 1 | epoch 158 | 0.003 | 0.000 | 0.985\n",
      "fold 1 | epoch 159 | 0.003 | 0.000 | 0.986\n",
      "fold 1 | epoch 160 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 161 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 162 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 163 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 164 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 165 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 166 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 167 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 168 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 169 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 170 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 171 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 172 | 0.003 | 0.000 | 0.989 | network improved\n",
      "fold 1 | epoch 173 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 174 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 175 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 176 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 177 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 178 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 179 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 180 | 0.003 | 0.000 | 0.990\n",
      "fold 1 | epoch 181 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 182 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 183 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 184 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 185 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 186 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 187 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 188 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 189 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 190 | 0.003 | 0.000 | 0.990\n",
      "fold 1 | epoch 191 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 192 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 193 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 194 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 195 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 196 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 197 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 198 | 0.003 | 0.000 | 0.987\n",
      "fold 1 | epoch 199 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 200 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 201 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 202 | 0.003 | 0.000 | 0.990 | network improved\n",
      "fold 1 | epoch 203 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 204 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 205 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 206 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 207 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 208 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 209 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 210 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 211 | 0.003 | 0.000 | 0.990 | network improved\n",
      "fold 1 | epoch 212 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 213 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 214 | 0.003 | 0.000 | 0.991\n",
      "fold 1 | epoch 215 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 216 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 217 | 0.003 | 0.000 | 0.988\n",
      "fold 1 | epoch 218 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 219 | 0.003 | 0.000 | 0.990\n",
      "fold 1 | epoch 220 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 221 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 222 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 223 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 224 | 0.002 | 0.000 | 0.989\n",
      "fold 1 | epoch 225 | 0.003 | 0.000 | 0.990 | network improved\n",
      "fold 1 | epoch 226 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 227 | 0.003 | 0.000 | 0.990\n",
      "fold 1 | epoch 228 | 0.003 | 0.000 | 0.990\n",
      "fold 1 | epoch 229 | 0.002 | 0.000 | 0.989\n",
      "fold 1 | epoch 230 | 0.003 | 0.000 | 0.990 | network improved\n",
      "fold 1 | epoch 231 | 0.002 | 0.000 | 0.990\n",
      "fold 1 | epoch 232 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 233 | 0.003 | 0.000 | 0.990\n",
      "fold 1 | epoch 234 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 235 | 0.003 | 0.000 | 0.990\n",
      "fold 1 | epoch 236 | 0.003 | 0.000 | 0.991\n",
      "fold 1 | epoch 237 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 238 | 0.002 | 0.000 | 0.989\n",
      "fold 1 | epoch 239 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 240 | 0.003 | 0.000 | 0.989\n",
      "fold 1 | epoch 241 | 0.002 | 0.000 | 0.991\n",
      "fold 1 | epoch 242 | 0.002 | 0.000 | 0.990\n",
      "fold 1 | epoch 243 | 0.002 | 0.000 | 0.988\n",
      "fold 1 | epoch 244 | 0.002 | 0.000 | 0.991 | network improved\n",
      "fold 1 | epoch 245 | 0.002 | 0.000 | 0.990\n",
      "fold 1 | epoch 246 | 0.002 | 0.000 | 0.990\n",
      "fold 1 | epoch 247 | 0.002 | 0.000 | 0.990\n",
      "fold 1 | epoch 248 | 0.002 | 0.000 | 0.990\n",
      "fold 1 | epoch 249 | 0.002 | 0.000 | 0.989\n",
      "fold 1 | epoch 250 | 0.002 | 0.000 | 0.990\n",
      "fold 2 | epoch 1 | 0.089 | 0.016 | 0.512 | network improved\n",
      "fold 2 | epoch 2 | 0.064 | 0.011 | 0.705 | network improved\n",
      "fold 2 | epoch 3 | 0.047 | 0.007 | 0.798 | network improved\n",
      "fold 2 | epoch 4 | 0.036 | 0.006 | 0.845 | network improved\n",
      "fold 2 | epoch 5 | 0.029 | 0.004 | 0.881 | network improved\n",
      "fold 2 | epoch 6 | 0.025 | 0.004 | 0.898 | network improved\n",
      "fold 2 | epoch 7 | 0.022 | 0.003 | 0.909 | network improved\n",
      "fold 2 | epoch 8 | 0.020 | 0.003 | 0.918 | network improved\n",
      "fold 2 | epoch 9 | 0.018 | 0.003 | 0.926 | network improved\n",
      "fold 2 | epoch 10 | 0.017 | 0.002 | 0.933 | network improved\n",
      "fold 2 | epoch 11 | 0.015 | 0.002 | 0.936 | network improved\n",
      "fold 2 | epoch 12 | 0.014 | 0.002 | 0.942 | network improved\n",
      "fold 2 | epoch 13 | 0.014 | 0.002 | 0.947 | network improved\n",
      "fold 2 | epoch 14 | 0.013 | 0.002 | 0.945 | network improved\n",
      "fold 2 | epoch 15 | 0.012 | 0.002 | 0.948 | network improved\n",
      "fold 2 | epoch 16 | 0.012 | 0.002 | 0.951 | network improved\n",
      "fold 2 | epoch 17 | 0.011 | 0.002 | 0.953 | network improved\n",
      "fold 2 | epoch 18 | 0.011 | 0.001 | 0.954 | network improved\n",
      "fold 2 | epoch 19 | 0.011 | 0.001 | 0.956 | network improved\n",
      "fold 2 | epoch 20 | 0.010 | 0.001 | 0.960 | network improved\n",
      "fold 2 | epoch 21 | 0.010 | 0.001 | 0.960 | network improved\n",
      "fold 2 | epoch 22 | 0.010 | 0.001 | 0.961 | network improved\n",
      "fold 2 | epoch 23 | 0.009 | 0.001 | 0.964 | network improved\n",
      "fold 2 | epoch 24 | 0.009 | 0.001 | 0.962\n",
      "fold 2 | epoch 25 | 0.009 | 0.001 | 0.961\n",
      "fold 2 | epoch 26 | 0.008 | 0.001 | 0.965 | network improved\n",
      "fold 2 | epoch 27 | 0.008 | 0.001 | 0.965 | network improved\n",
      "fold 2 | epoch 28 | 0.008 | 0.001 | 0.968 | network improved\n",
      "fold 2 | epoch 29 | 0.008 | 0.001 | 0.967\n",
      "fold 2 | epoch 30 | 0.008 | 0.001 | 0.966\n",
      "fold 2 | epoch 31 | 0.008 | 0.001 | 0.967\n",
      "fold 2 | epoch 32 | 0.007 | 0.001 | 0.968 | network improved\n",
      "fold 2 | epoch 33 | 0.007 | 0.001 | 0.968 | network improved\n",
      "fold 2 | epoch 34 | 0.007 | 0.001 | 0.971\n",
      "fold 2 | epoch 35 | 0.007 | 0.001 | 0.971 | network improved\n",
      "fold 2 | epoch 36 | 0.007 | 0.001 | 0.972 | network improved\n",
      "fold 2 | epoch 37 | 0.007 | 0.001 | 0.970\n",
      "fold 2 | epoch 38 | 0.007 | 0.001 | 0.972 | network improved\n",
      "fold 2 | epoch 39 | 0.007 | 0.001 | 0.971 | network improved\n",
      "fold 2 | epoch 40 | 0.006 | 0.001 | 0.972 | network improved\n",
      "fold 2 | epoch 41 | 0.006 | 0.001 | 0.971\n",
      "fold 2 | epoch 42 | 0.006 | 0.001 | 0.971\n",
      "fold 2 | epoch 43 | 0.006 | 0.001 | 0.975 | network improved\n",
      "fold 2 | epoch 44 | 0.006 | 0.001 | 0.973 | network improved\n",
      "fold 2 | epoch 45 | 0.006 | 0.001 | 0.974 | network improved\n",
      "fold 2 | epoch 46 | 0.006 | 0.001 | 0.975\n",
      "fold 2 | epoch 47 | 0.006 | 0.001 | 0.977 | network improved\n",
      "fold 2 | epoch 48 | 0.006 | 0.001 | 0.976\n",
      "fold 2 | epoch 49 | 0.006 | 0.001 | 0.976\n",
      "fold 2 | epoch 50 | 0.006 | 0.001 | 0.978 | network improved\n",
      "fold 2 | epoch 51 | 0.006 | 0.001 | 0.975\n",
      "fold 2 | epoch 52 | 0.006 | 0.001 | 0.976\n",
      "fold 2 | epoch 53 | 0.006 | 0.001 | 0.977\n",
      "fold 2 | epoch 54 | 0.006 | 0.001 | 0.976 | network improved\n",
      "fold 2 | epoch 55 | 0.005 | 0.001 | 0.977\n",
      "fold 2 | epoch 56 | 0.005 | 0.001 | 0.976\n",
      "fold 2 | epoch 57 | 0.005 | 0.001 | 0.978 | network improved\n",
      "fold 2 | epoch 58 | 0.005 | 0.001 | 0.977\n",
      "fold 2 | epoch 59 | 0.005 | 0.001 | 0.979\n",
      "fold 2 | epoch 60 | 0.005 | 0.001 | 0.976\n",
      "fold 2 | epoch 61 | 0.005 | 0.001 | 0.981\n",
      "fold 2 | epoch 62 | 0.005 | 0.001 | 0.976\n",
      "fold 2 | epoch 63 | 0.005 | 0.001 | 0.980\n",
      "fold 2 | epoch 64 | 0.005 | 0.001 | 0.977\n",
      "fold 2 | epoch 65 | 0.005 | 0.001 | 0.979\n",
      "fold 2 | epoch 66 | 0.005 | 0.001 | 0.980\n",
      "fold 2 | epoch 67 | 0.005 | 0.001 | 0.980\n",
      "fold 2 | epoch 68 | 0.005 | 0.001 | 0.982 | network improved\n",
      "fold 2 | epoch 69 | 0.005 | 0.001 | 0.980\n",
      "fold 2 | epoch 70 | 0.005 | 0.001 | 0.980\n",
      "fold 2 | epoch 71 | 0.005 | 0.001 | 0.980\n",
      "fold 2 | epoch 72 | 0.005 | 0.001 | 0.979\n",
      "fold 2 | epoch 73 | 0.005 | 0.001 | 0.980\n",
      "fold 2 | epoch 74 | 0.005 | 0.001 | 0.979\n",
      "fold 2 | epoch 75 | 0.005 | 0.001 | 0.980\n",
      "fold 2 | epoch 76 | 0.004 | 0.001 | 0.979 | network improved\n",
      "fold 2 | epoch 77 | 0.004 | 0.001 | 0.981\n",
      "fold 2 | epoch 78 | 0.005 | 0.001 | 0.981\n",
      "fold 2 | epoch 79 | 0.005 | 0.001 | 0.981\n",
      "fold 2 | epoch 80 | 0.004 | 0.001 | 0.981\n",
      "fold 2 | epoch 81 | 0.004 | 0.001 | 0.982 | network improved\n",
      "fold 2 | epoch 82 | 0.005 | 0.001 | 0.983\n",
      "fold 2 | epoch 83 | 0.004 | 0.001 | 0.980\n",
      "fold 2 | epoch 84 | 0.004 | 0.001 | 0.983\n",
      "fold 2 | epoch 85 | 0.004 | 0.001 | 0.981\n",
      "fold 2 | epoch 86 | 0.004 | 0.001 | 0.982\n",
      "fold 2 | epoch 87 | 0.004 | 0.001 | 0.980\n",
      "fold 2 | epoch 88 | 0.004 | 0.001 | 0.981\n",
      "fold 2 | epoch 89 | 0.004 | 0.001 | 0.982\n",
      "fold 2 | epoch 90 | 0.004 | 0.001 | 0.982 | network improved\n",
      "fold 2 | epoch 91 | 0.004 | 0.001 | 0.981\n",
      "fold 2 | epoch 92 | 0.004 | 0.001 | 0.983 | network improved\n",
      "fold 2 | epoch 93 | 0.004 | 0.001 | 0.983\n",
      "fold 2 | epoch 94 | 0.004 | 0.001 | 0.984 | network improved\n",
      "fold 2 | epoch 95 | 0.004 | 0.001 | 0.983\n",
      "fold 2 | epoch 96 | 0.004 | 0.001 | 0.983 | network improved\n",
      "fold 2 | epoch 97 | 0.004 | 0.001 | 0.983\n",
      "fold 2 | epoch 98 | 0.004 | 0.001 | 0.984\n",
      "fold 2 | epoch 99 | 0.004 | 0.001 | 0.982\n",
      "fold 2 | epoch 100 | 0.004 | 0.001 | 0.983\n",
      "fold 2 | epoch 101 | 0.004 | 0.000 | 0.984 | network improved\n",
      "fold 2 | epoch 102 | 0.004 | 0.001 | 0.984\n",
      "fold 2 | epoch 103 | 0.004 | 0.000 | 0.984\n",
      "fold 2 | epoch 104 | 0.004 | 0.001 | 0.983\n",
      "fold 2 | epoch 105 | 0.004 | 0.000 | 0.985 | network improved\n",
      "fold 2 | epoch 106 | 0.004 | 0.001 | 0.984\n",
      "fold 2 | epoch 107 | 0.004 | 0.001 | 0.982\n",
      "fold 2 | epoch 108 | 0.004 | 0.000 | 0.983\n",
      "fold 2 | epoch 109 | 0.004 | 0.000 | 0.983\n",
      "fold 2 | epoch 110 | 0.004 | 0.000 | 0.983\n",
      "fold 2 | epoch 111 | 0.004 | 0.000 | 0.984\n",
      "fold 2 | epoch 112 | 0.004 | 0.001 | 0.982\n",
      "fold 2 | epoch 113 | 0.004 | 0.000 | 0.986 | network improved\n",
      "fold 2 | epoch 114 | 0.004 | 0.000 | 0.984\n",
      "fold 2 | epoch 115 | 0.004 | 0.001 | 0.983\n",
      "fold 2 | epoch 116 | 0.004 | 0.000 | 0.984\n",
      "fold 2 | epoch 117 | 0.004 | 0.000 | 0.985\n",
      "fold 2 | epoch 118 | 0.004 | 0.000 | 0.984\n",
      "fold 2 | epoch 119 | 0.004 | 0.000 | 0.986 | network improved\n",
      "fold 2 | epoch 120 | 0.004 | 0.000 | 0.984\n",
      "fold 2 | epoch 121 | 0.004 | 0.000 | 0.986\n",
      "fold 2 | epoch 122 | 0.004 | 0.000 | 0.985\n",
      "fold 2 | epoch 123 | 0.004 | 0.000 | 0.986\n",
      "fold 2 | epoch 124 | 0.004 | 0.000 | 0.984\n",
      "fold 2 | epoch 125 | 0.004 | 0.000 | 0.986\n",
      "fold 2 | epoch 126 | 0.004 | 0.000 | 0.986 | network improved\n",
      "fold 2 | epoch 127 | 0.003 | 0.000 | 0.985\n",
      "fold 2 | epoch 128 | 0.003 | 0.000 | 0.984\n",
      "fold 2 | epoch 129 | 0.004 | 0.000 | 0.984\n",
      "fold 2 | epoch 130 | 0.003 | 0.000 | 0.983\n",
      "fold 2 | epoch 131 | 0.004 | 0.000 | 0.984\n",
      "fold 2 | epoch 132 | 0.003 | 0.000 | 0.985\n",
      "fold 2 | epoch 133 | 0.003 | 0.000 | 0.985\n",
      "fold 2 | epoch 134 | 0.003 | 0.000 | 0.985\n",
      "fold 2 | epoch 135 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 136 | 0.003 | 0.000 | 0.986 | network improved\n",
      "fold 2 | epoch 137 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 138 | 0.004 | 0.000 | 0.987\n",
      "fold 2 | epoch 139 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 140 | 0.003 | 0.000 | 0.987 | network improved\n",
      "fold 2 | epoch 141 | 0.003 | 0.000 | 0.985\n",
      "fold 2 | epoch 142 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 143 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 144 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 145 | 0.003 | 0.000 | 0.985\n",
      "fold 2 | epoch 146 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 147 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 148 | 0.003 | 0.000 | 0.985\n",
      "fold 2 | epoch 149 | 0.003 | 0.000 | 0.985\n",
      "fold 2 | epoch 150 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 151 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 152 | 0.003 | 0.000 | 0.987 | network improved\n",
      "fold 2 | epoch 153 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 154 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 155 | 0.003 | 0.000 | 0.985\n",
      "fold 2 | epoch 156 | 0.003 | 0.000 | 0.985\n",
      "fold 2 | epoch 157 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 158 | 0.003 | 0.000 | 0.989 | network improved\n",
      "fold 2 | epoch 159 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 160 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 161 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 162 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 163 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 164 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 165 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 166 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 167 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 168 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 169 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 170 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 171 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 172 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 173 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 174 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 175 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 176 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 177 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 178 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 179 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 180 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 181 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 182 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 183 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 184 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 185 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 186 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 187 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 188 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 189 | 0.003 | 0.000 | 0.990 | network improved\n",
      "fold 2 | epoch 190 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 191 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 192 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 193 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 194 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 195 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 196 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 197 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 198 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 199 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 200 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 201 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 202 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 203 | 0.003 | 0.000 | 0.990 | network improved\n",
      "fold 2 | epoch 204 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 205 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 206 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 207 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 208 | 0.003 | 0.000 | 0.990\n",
      "fold 2 | epoch 209 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 210 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 211 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 212 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 213 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 214 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 215 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 216 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 217 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 218 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 219 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 220 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 221 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 222 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 223 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 224 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 225 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 226 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 227 | 0.003 | 0.000 | 0.987\n",
      "fold 2 | epoch 228 | 0.003 | 0.000 | 0.990\n",
      "fold 2 | epoch 229 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 230 | 0.003 | 0.000 | 0.986\n",
      "fold 2 | epoch 231 | 0.003 | 0.000 | 0.990\n",
      "fold 2 | epoch 232 | 0.002 | 0.000 | 0.990\n",
      "fold 2 | epoch 233 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 234 | 0.003 | 0.000 | 0.989 | network improved\n",
      "fold 2 | epoch 235 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 236 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 237 | 0.003 | 0.000 | 0.990\n",
      "fold 2 | epoch 238 | 0.003 | 0.000 | 0.988\n",
      "fold 2 | epoch 239 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 240 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 241 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 242 | 0.003 | 0.000 | 0.990\n",
      "fold 2 | epoch 243 | 0.003 | 0.000 | 0.990\n",
      "fold 2 | epoch 244 | 0.002 | 0.000 | 0.990\n",
      "fold 2 | epoch 245 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 246 | 0.003 | 0.000 | 0.990\n",
      "fold 2 | epoch 247 | 0.003 | 0.000 | 0.990\n",
      "fold 2 | epoch 248 | 0.002 | 0.000 | 0.989\n",
      "fold 2 | epoch 249 | 0.003 | 0.000 | 0.989\n",
      "fold 2 | epoch 250 | 0.002 | 0.000 | 0.990\n",
      "fold 3 | epoch 1 | 0.085 | 0.014 | 0.589 | network improved\n",
      "fold 3 | epoch 2 | 0.056 | 0.009 | 0.773 | network improved\n",
      "fold 3 | epoch 3 | 0.040 | 0.006 | 0.844 | network improved\n",
      "fold 3 | epoch 4 | 0.031 | 0.005 | 0.877 | network improved\n",
      "fold 3 | epoch 5 | 0.026 | 0.004 | 0.900 | network improved\n",
      "fold 3 | epoch 6 | 0.023 | 0.003 | 0.912 | network improved\n",
      "fold 3 | epoch 7 | 0.020 | 0.003 | 0.922 | network improved\n",
      "fold 3 | epoch 8 | 0.018 | 0.002 | 0.931 | network improved\n",
      "fold 3 | epoch 9 | 0.017 | 0.002 | 0.936 | network improved\n",
      "fold 3 | epoch 10 | 0.015 | 0.002 | 0.942 | network improved\n",
      "fold 3 | epoch 11 | 0.014 | 0.002 | 0.946 | network improved\n",
      "fold 3 | epoch 12 | 0.013 | 0.002 | 0.950 | network improved\n",
      "fold 3 | epoch 13 | 0.013 | 0.002 | 0.952 | network improved\n",
      "fold 3 | epoch 14 | 0.012 | 0.002 | 0.953 | network improved\n",
      "fold 3 | epoch 15 | 0.011 | 0.002 | 0.953 | network improved\n",
      "fold 3 | epoch 16 | 0.011 | 0.001 | 0.955 | network improved\n",
      "fold 3 | epoch 17 | 0.011 | 0.001 | 0.957 | network improved\n",
      "fold 3 | epoch 18 | 0.010 | 0.001 | 0.965 | network improved\n",
      "fold 3 | epoch 19 | 0.010 | 0.001 | 0.963\n",
      "fold 3 | epoch 20 | 0.010 | 0.001 | 0.964\n",
      "fold 3 | epoch 21 | 0.009 | 0.001 | 0.964 | network improved\n",
      "fold 3 | epoch 22 | 0.009 | 0.001 | 0.968 | network improved\n",
      "fold 3 | epoch 23 | 0.009 | 0.001 | 0.965\n",
      "fold 3 | epoch 24 | 0.009 | 0.001 | 0.969 | network improved\n",
      "fold 3 | epoch 25 | 0.008 | 0.001 | 0.969\n",
      "fold 3 | epoch 26 | 0.008 | 0.001 | 0.967\n",
      "fold 3 | epoch 27 | 0.008 | 0.001 | 0.968 | network improved\n",
      "fold 3 | epoch 28 | 0.008 | 0.001 | 0.968\n",
      "fold 3 | epoch 29 | 0.008 | 0.001 | 0.969 | network improved\n",
      "fold 3 | epoch 30 | 0.008 | 0.001 | 0.969\n",
      "fold 3 | epoch 31 | 0.007 | 0.001 | 0.970 | network improved\n",
      "fold 3 | epoch 32 | 0.007 | 0.001 | 0.972 | network improved\n",
      "fold 3 | epoch 33 | 0.007 | 0.001 | 0.974\n",
      "fold 3 | epoch 34 | 0.007 | 0.001 | 0.977 | network improved\n",
      "fold 3 | epoch 35 | 0.007 | 0.001 | 0.973\n",
      "fold 3 | epoch 36 | 0.007 | 0.001 | 0.975\n",
      "fold 3 | epoch 37 | 0.007 | 0.001 | 0.973\n",
      "fold 3 | epoch 38 | 0.006 | 0.001 | 0.974\n",
      "fold 3 | epoch 39 | 0.006 | 0.001 | 0.975\n",
      "fold 3 | epoch 40 | 0.006 | 0.001 | 0.975\n",
      "fold 3 | epoch 41 | 0.006 | 0.001 | 0.975\n",
      "fold 3 | epoch 42 | 0.006 | 0.001 | 0.976 | network improved\n",
      "fold 3 | epoch 43 | 0.006 | 0.001 | 0.976\n",
      "fold 3 | epoch 44 | 0.006 | 0.001 | 0.978 | network improved\n",
      "fold 3 | epoch 45 | 0.006 | 0.001 | 0.977 | network improved\n",
      "fold 3 | epoch 46 | 0.006 | 0.001 | 0.978\n",
      "fold 3 | epoch 47 | 0.006 | 0.001 | 0.979\n",
      "fold 3 | epoch 48 | 0.006 | 0.001 | 0.978\n",
      "fold 3 | epoch 49 | 0.006 | 0.001 | 0.979 | network improved\n",
      "fold 3 | epoch 50 | 0.005 | 0.001 | 0.978 | network improved\n",
      "fold 3 | epoch 51 | 0.005 | 0.001 | 0.978\n",
      "fold 3 | epoch 52 | 0.006 | 0.001 | 0.980\n",
      "fold 3 | epoch 53 | 0.005 | 0.001 | 0.979 | network improved\n",
      "fold 3 | epoch 54 | 0.005 | 0.001 | 0.978\n",
      "fold 3 | epoch 55 | 0.005 | 0.001 | 0.981 | network improved\n",
      "fold 3 | epoch 56 | 0.005 | 0.001 | 0.979\n",
      "fold 3 | epoch 57 | 0.005 | 0.001 | 0.979\n",
      "fold 3 | epoch 58 | 0.005 | 0.001 | 0.979\n",
      "fold 3 | epoch 59 | 0.005 | 0.001 | 0.980\n",
      "fold 3 | epoch 60 | 0.005 | 0.001 | 0.979\n",
      "fold 3 | epoch 61 | 0.005 | 0.001 | 0.980 | network improved\n",
      "fold 3 | epoch 62 | 0.005 | 0.001 | 0.979\n",
      "fold 3 | epoch 63 | 0.005 | 0.001 | 0.979\n",
      "fold 3 | epoch 64 | 0.005 | 0.001 | 0.980\n",
      "fold 3 | epoch 65 | 0.005 | 0.001 | 0.979\n",
      "fold 3 | epoch 66 | 0.005 | 0.001 | 0.979\n",
      "fold 3 | epoch 67 | 0.005 | 0.001 | 0.981 | network improved\n",
      "fold 3 | epoch 68 | 0.005 | 0.001 | 0.980\n",
      "fold 3 | epoch 69 | 0.005 | 0.001 | 0.982 | network improved\n",
      "fold 3 | epoch 70 | 0.005 | 0.001 | 0.983\n",
      "fold 3 | epoch 71 | 0.005 | 0.001 | 0.983\n",
      "fold 3 | epoch 72 | 0.005 | 0.001 | 0.985\n",
      "fold 3 | epoch 73 | 0.005 | 0.001 | 0.982\n",
      "fold 3 | epoch 74 | 0.004 | 0.001 | 0.981 | network improved\n",
      "fold 3 | epoch 75 | 0.005 | 0.001 | 0.980\n",
      "fold 3 | epoch 76 | 0.004 | 0.001 | 0.981\n",
      "fold 3 | epoch 77 | 0.004 | 0.001 | 0.983 | network improved\n",
      "fold 3 | epoch 78 | 0.004 | 0.001 | 0.983\n",
      "fold 3 | epoch 79 | 0.004 | 0.001 | 0.984\n",
      "fold 3 | epoch 80 | 0.004 | 0.001 | 0.981\n",
      "fold 3 | epoch 81 | 0.004 | 0.001 | 0.984\n",
      "fold 3 | epoch 82 | 0.004 | 0.001 | 0.981\n",
      "fold 3 | epoch 83 | 0.004 | 0.001 | 0.982\n",
      "fold 3 | epoch 84 | 0.004 | 0.001 | 0.982\n",
      "fold 3 | epoch 85 | 0.004 | 0.001 | 0.982 | network improved\n",
      "fold 3 | epoch 86 | 0.004 | 0.001 | 0.985 | network improved\n",
      "fold 3 | epoch 87 | 0.004 | 0.001 | 0.984\n",
      "fold 3 | epoch 88 | 0.004 | 0.001 | 0.982\n",
      "fold 3 | epoch 89 | 0.004 | 0.001 | 0.984\n",
      "fold 3 | epoch 90 | 0.004 | 0.001 | 0.983\n",
      "fold 3 | epoch 91 | 0.004 | 0.001 | 0.982\n",
      "fold 3 | epoch 92 | 0.004 | 0.001 | 0.983\n",
      "fold 3 | epoch 93 | 0.004 | 0.001 | 0.984 | network improved\n",
      "fold 3 | epoch 94 | 0.004 | 0.001 | 0.984\n",
      "fold 3 | epoch 95 | 0.004 | 0.001 | 0.984\n",
      "fold 3 | epoch 96 | 0.004 | 0.001 | 0.983\n",
      "fold 3 | epoch 97 | 0.004 | 0.001 | 0.983\n",
      "fold 3 | epoch 98 | 0.004 | 0.001 | 0.984\n",
      "fold 3 | epoch 99 | 0.004 | 0.001 | 0.983\n",
      "fold 3 | epoch 100 | 0.004 | 0.001 | 0.983\n",
      "fold 3 | epoch 101 | 0.004 | 0.001 | 0.982\n",
      "fold 3 | epoch 102 | 0.004 | 0.001 | 0.985\n",
      "fold 3 | epoch 103 | 0.004 | 0.000 | 0.985\n",
      "fold 3 | epoch 104 | 0.004 | 0.000 | 0.985 | network improved\n",
      "fold 3 | epoch 105 | 0.004 | 0.001 | 0.983\n",
      "fold 3 | epoch 106 | 0.004 | 0.000 | 0.984\n",
      "fold 3 | epoch 107 | 0.004 | 0.001 | 0.984\n",
      "fold 3 | epoch 108 | 0.004 | 0.001 | 0.981\n",
      "fold 3 | epoch 109 | 0.004 | 0.000 | 0.985 | network improved\n",
      "fold 3 | epoch 110 | 0.004 | 0.001 | 0.984\n",
      "fold 3 | epoch 111 | 0.004 | 0.000 | 0.986 | network improved\n",
      "fold 3 | epoch 112 | 0.004 | 0.000 | 0.986\n",
      "fold 3 | epoch 113 | 0.004 | 0.000 | 0.985\n",
      "fold 3 | epoch 114 | 0.004 | 0.000 | 0.984\n",
      "fold 3 | epoch 115 | 0.004 | 0.000 | 0.984\n",
      "fold 3 | epoch 116 | 0.003 | 0.000 | 0.984 | network improved\n",
      "fold 3 | epoch 117 | 0.004 | 0.000 | 0.985\n",
      "fold 3 | epoch 118 | 0.004 | 0.001 | 0.985\n",
      "fold 3 | epoch 119 | 0.004 | 0.000 | 0.985\n",
      "fold 3 | epoch 120 | 0.004 | 0.000 | 0.985\n",
      "fold 3 | epoch 121 | 0.003 | 0.000 | 0.985 | network improved\n",
      "fold 3 | epoch 122 | 0.004 | 0.000 | 0.985\n",
      "fold 3 | epoch 123 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 124 | 0.003 | 0.000 | 0.985\n",
      "fold 3 | epoch 125 | 0.004 | 0.000 | 0.986\n",
      "fold 3 | epoch 126 | 0.003 | 0.000 | 0.985\n",
      "fold 3 | epoch 127 | 0.003 | 0.000 | 0.986 | network improved\n",
      "fold 3 | epoch 128 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 129 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 130 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 131 | 0.003 | 0.000 | 0.985\n",
      "fold 3 | epoch 132 | 0.003 | 0.000 | 0.988 | network improved\n",
      "fold 3 | epoch 133 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 134 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 135 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 136 | 0.003 | 0.000 | 0.984\n",
      "fold 3 | epoch 137 | 0.003 | 0.000 | 0.987 | network improved\n",
      "fold 3 | epoch 138 | 0.003 | 0.000 | 0.985\n",
      "fold 3 | epoch 139 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 140 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 141 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 142 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 143 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 144 | 0.003 | 0.000 | 0.985\n",
      "fold 3 | epoch 145 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 146 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 147 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 148 | 0.003 | 0.000 | 0.985\n",
      "fold 3 | epoch 149 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 150 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 151 | 0.003 | 0.000 | 0.985\n",
      "fold 3 | epoch 152 | 0.003 | 0.000 | 0.985\n",
      "fold 3 | epoch 153 | 0.003 | 0.000 | 0.987 | network improved\n",
      "fold 3 | epoch 154 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 155 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 156 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 157 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 158 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 159 | 0.003 | 0.000 | 0.987 | network improved\n",
      "fold 3 | epoch 160 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 161 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 162 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 163 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 164 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 165 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 166 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 167 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 168 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 169 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 170 | 0.003 | 0.000 | 0.985\n",
      "fold 3 | epoch 171 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 172 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 173 | 0.003 | 0.000 | 0.988 | network improved\n",
      "fold 3 | epoch 174 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 175 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 176 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 177 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 178 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 179 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 180 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 181 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 182 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 183 | 0.003 | 0.000 | 0.989\n",
      "fold 3 | epoch 184 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 185 | 0.003 | 0.000 | 0.987 | network improved\n",
      "fold 3 | epoch 186 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 187 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 188 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 189 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 190 | 0.003 | 0.000 | 0.988 | network improved\n",
      "fold 3 | epoch 191 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 192 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 193 | 0.003 | 0.000 | 0.989 | network improved\n",
      "fold 3 | epoch 194 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 195 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 196 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 197 | 0.003 | 0.000 | 0.989\n",
      "fold 3 | epoch 198 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 199 | 0.003 | 0.000 | 0.986\n",
      "fold 3 | epoch 200 | 0.003 | 0.000 | 0.989\n",
      "fold 3 | epoch 201 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 202 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 203 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 204 | 0.003 | 0.000 | 0.989\n",
      "fold 3 | epoch 205 | 0.003 | 0.000 | 0.990\n",
      "fold 3 | epoch 206 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 207 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 208 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 209 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 210 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 211 | 0.003 | 0.000 | 0.989\n",
      "fold 3 | epoch 212 | 0.003 | 0.000 | 0.989\n",
      "fold 3 | epoch 213 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 214 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 215 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 216 | 0.003 | 0.000 | 0.989\n",
      "fold 3 | epoch 217 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 218 | 0.003 | 0.000 | 0.989\n",
      "fold 3 | epoch 219 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 220 | 0.003 | 0.000 | 0.989\n",
      "fold 3 | epoch 221 | 0.002 | 0.000 | 0.989\n",
      "fold 3 | epoch 222 | 0.003 | 0.000 | 0.989\n",
      "fold 3 | epoch 223 | 0.003 | 0.000 | 0.989\n",
      "fold 3 | epoch 224 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 225 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 226 | 0.003 | 0.000 | 0.990\n",
      "fold 3 | epoch 227 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 228 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 229 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 230 | 0.003 | 0.000 | 0.990\n",
      "fold 3 | epoch 231 | 0.002 | 0.000 | 0.987\n",
      "fold 3 | epoch 232 | 0.002 | 0.000 | 0.988\n",
      "fold 3 | epoch 233 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 234 | 0.002 | 0.000 | 0.990\n",
      "fold 3 | epoch 235 | 0.002 | 0.000 | 0.990\n",
      "fold 3 | epoch 236 | 0.003 | 0.000 | 0.989\n",
      "fold 3 | epoch 237 | 0.002 | 0.000 | 0.989\n",
      "fold 3 | epoch 238 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 239 | 0.003 | 0.000 | 0.990\n",
      "fold 3 | epoch 240 | 0.003 | 0.000 | 0.989\n",
      "fold 3 | epoch 241 | 0.003 | 0.000 | 0.988\n",
      "fold 3 | epoch 242 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 243 | 0.002 | 0.000 | 0.988\n",
      "fold 3 | epoch 244 | 0.002 | 0.000 | 0.990\n",
      "fold 3 | epoch 245 | 0.003 | 0.000 | 0.987\n",
      "fold 3 | epoch 246 | 0.002 | 0.000 | 0.990\n",
      "fold 3 | epoch 247 | 0.002 | 0.000 | 0.987\n",
      "fold 3 | epoch 248 | 0.002 | 0.000 | 0.989\n",
      "fold 3 | epoch 249 | 0.003 | 0.000 | 0.990\n",
      "fold 3 | epoch 250 | 0.002 | 0.000 | 0.989\n",
      "fold 4 | epoch 1 | 0.088 | 0.015 | 0.559 | network improved\n",
      "fold 4 | epoch 2 | 0.062 | 0.010 | 0.748 | network improved\n",
      "fold 4 | epoch 3 | 0.045 | 0.007 | 0.811 | network improved\n",
      "fold 4 | epoch 4 | 0.036 | 0.006 | 0.844 | network improved\n",
      "fold 4 | epoch 5 | 0.030 | 0.005 | 0.870 | network improved\n",
      "fold 4 | epoch 6 | 0.026 | 0.004 | 0.883 | network improved\n",
      "fold 4 | epoch 7 | 0.023 | 0.003 | 0.901 | network improved\n",
      "fold 4 | epoch 8 | 0.021 | 0.003 | 0.911 | network improved\n",
      "fold 4 | epoch 9 | 0.019 | 0.003 | 0.921 | network improved\n",
      "fold 4 | epoch 10 | 0.018 | 0.002 | 0.931 | network improved\n",
      "fold 4 | epoch 11 | 0.016 | 0.002 | 0.929 | network improved\n",
      "fold 4 | epoch 12 | 0.015 | 0.002 | 0.936 | network improved\n",
      "fold 4 | epoch 13 | 0.014 | 0.002 | 0.943 | network improved\n",
      "fold 4 | epoch 14 | 0.013 | 0.002 | 0.946 | network improved\n",
      "fold 4 | epoch 15 | 0.013 | 0.002 | 0.948 | network improved\n",
      "fold 4 | epoch 16 | 0.012 | 0.002 | 0.954 | network improved\n",
      "fold 4 | epoch 17 | 0.012 | 0.001 | 0.955 | network improved\n",
      "fold 4 | epoch 18 | 0.011 | 0.001 | 0.956 | network improved\n",
      "fold 4 | epoch 19 | 0.011 | 0.001 | 0.957 | network improved\n",
      "fold 4 | epoch 20 | 0.010 | 0.001 | 0.958 | network improved\n",
      "fold 4 | epoch 21 | 0.010 | 0.001 | 0.959 | network improved\n",
      "fold 4 | epoch 22 | 0.010 | 0.001 | 0.959 | network improved\n",
      "fold 4 | epoch 23 | 0.009 | 0.001 | 0.961 | network improved\n",
      "fold 4 | epoch 24 | 0.009 | 0.001 | 0.961 | network improved\n",
      "fold 4 | epoch 25 | 0.009 | 0.001 | 0.964 | network improved\n",
      "fold 4 | epoch 26 | 0.008 | 0.001 | 0.966 | network improved\n",
      "fold 4 | epoch 27 | 0.008 | 0.001 | 0.966 | network improved\n",
      "fold 4 | epoch 28 | 0.008 | 0.001 | 0.966 | network improved\n",
      "fold 4 | epoch 29 | 0.008 | 0.001 | 0.968 | network improved\n",
      "fold 4 | epoch 30 | 0.008 | 0.001 | 0.966\n",
      "fold 4 | epoch 31 | 0.007 | 0.001 | 0.969 | network improved\n",
      "fold 4 | epoch 32 | 0.007 | 0.001 | 0.970 | network improved\n",
      "fold 4 | epoch 33 | 0.007 | 0.001 | 0.971\n",
      "fold 4 | epoch 34 | 0.007 | 0.001 | 0.969 | network improved\n",
      "fold 4 | epoch 35 | 0.007 | 0.001 | 0.970 | network improved\n",
      "fold 4 | epoch 36 | 0.007 | 0.001 | 0.971 | network improved\n",
      "fold 4 | epoch 37 | 0.007 | 0.001 | 0.970 | network improved\n",
      "fold 4 | epoch 38 | 0.007 | 0.001 | 0.970 | network improved\n",
      "fold 4 | epoch 39 | 0.006 | 0.001 | 0.975\n",
      "fold 4 | epoch 40 | 0.006 | 0.001 | 0.974 | network improved\n",
      "fold 4 | epoch 41 | 0.006 | 0.001 | 0.974\n",
      "fold 4 | epoch 42 | 0.006 | 0.001 | 0.976 | network improved\n",
      "fold 4 | epoch 43 | 0.006 | 0.001 | 0.975 | network improved\n",
      "fold 4 | epoch 44 | 0.006 | 0.001 | 0.974\n",
      "fold 4 | epoch 45 | 0.006 | 0.001 | 0.976 | network improved\n",
      "fold 4 | epoch 46 | 0.006 | 0.001 | 0.974\n",
      "fold 4 | epoch 47 | 0.006 | 0.001 | 0.974\n",
      "fold 4 | epoch 48 | 0.006 | 0.001 | 0.975\n",
      "fold 4 | epoch 49 | 0.006 | 0.001 | 0.977 | network improved\n",
      "fold 4 | epoch 50 | 0.006 | 0.001 | 0.976\n",
      "fold 4 | epoch 51 | 0.006 | 0.001 | 0.975 | network improved\n",
      "fold 4 | epoch 52 | 0.006 | 0.001 | 0.978\n",
      "fold 4 | epoch 53 | 0.006 | 0.001 | 0.975\n",
      "fold 4 | epoch 54 | 0.005 | 0.001 | 0.976\n",
      "fold 4 | epoch 55 | 0.005 | 0.001 | 0.978\n",
      "fold 4 | epoch 56 | 0.005 | 0.001 | 0.978 | network improved\n",
      "fold 4 | epoch 57 | 0.005 | 0.001 | 0.976\n",
      "fold 4 | epoch 58 | 0.005 | 0.001 | 0.977\n",
      "fold 4 | epoch 59 | 0.005 | 0.001 | 0.976\n",
      "fold 4 | epoch 60 | 0.005 | 0.001 | 0.977\n",
      "fold 4 | epoch 61 | 0.005 | 0.001 | 0.980 | network improved\n",
      "fold 4 | epoch 62 | 0.005 | 0.001 | 0.978\n",
      "fold 4 | epoch 63 | 0.005 | 0.001 | 0.977\n",
      "fold 4 | epoch 64 | 0.005 | 0.001 | 0.980 | network improved\n",
      "fold 4 | epoch 65 | 0.005 | 0.001 | 0.980\n",
      "fold 4 | epoch 66 | 0.005 | 0.001 | 0.978\n",
      "fold 4 | epoch 67 | 0.005 | 0.001 | 0.979 | network improved\n",
      "fold 4 | epoch 68 | 0.005 | 0.001 | 0.980\n",
      "fold 4 | epoch 69 | 0.005 | 0.001 | 0.980\n",
      "fold 4 | epoch 70 | 0.005 | 0.001 | 0.978\n",
      "fold 4 | epoch 71 | 0.005 | 0.001 | 0.981\n",
      "fold 4 | epoch 72 | 0.005 | 0.001 | 0.979\n",
      "fold 4 | epoch 73 | 0.005 | 0.001 | 0.980 | network improved\n",
      "fold 4 | epoch 74 | 0.005 | 0.001 | 0.982 | network improved\n",
      "fold 4 | epoch 75 | 0.005 | 0.001 | 0.982\n",
      "fold 4 | epoch 76 | 0.005 | 0.001 | 0.981\n",
      "fold 4 | epoch 77 | 0.005 | 0.001 | 0.981 | network improved\n",
      "fold 4 | epoch 78 | 0.004 | 0.001 | 0.982\n",
      "fold 4 | epoch 79 | 0.004 | 0.001 | 0.981\n",
      "fold 4 | epoch 80 | 0.004 | 0.001 | 0.983 | network improved\n",
      "fold 4 | epoch 81 | 0.004 | 0.001 | 0.980\n",
      "fold 4 | epoch 82 | 0.004 | 0.001 | 0.981 | network improved\n",
      "fold 4 | epoch 83 | 0.004 | 0.001 | 0.981\n",
      "fold 4 | epoch 84 | 0.004 | 0.001 | 0.982\n",
      "fold 4 | epoch 85 | 0.004 | 0.001 | 0.982\n",
      "fold 4 | epoch 86 | 0.004 | 0.001 | 0.982\n",
      "fold 4 | epoch 87 | 0.004 | 0.001 | 0.980\n",
      "fold 4 | epoch 88 | 0.004 | 0.001 | 0.980\n",
      "fold 4 | epoch 89 | 0.004 | 0.001 | 0.982\n",
      "fold 4 | epoch 90 | 0.004 | 0.001 | 0.983 | network improved\n",
      "fold 4 | epoch 91 | 0.004 | 0.001 | 0.984\n",
      "fold 4 | epoch 92 | 0.004 | 0.001 | 0.983\n",
      "fold 4 | epoch 93 | 0.004 | 0.001 | 0.980\n",
      "fold 4 | epoch 94 | 0.004 | 0.001 | 0.983\n",
      "fold 4 | epoch 95 | 0.004 | 0.001 | 0.984 | network improved\n",
      "fold 4 | epoch 96 | 0.004 | 0.001 | 0.981\n",
      "fold 4 | epoch 97 | 0.004 | 0.001 | 0.983\n",
      "fold 4 | epoch 98 | 0.004 | 0.001 | 0.980\n",
      "fold 4 | epoch 99 | 0.004 | 0.001 | 0.983\n",
      "fold 4 | epoch 100 | 0.004 | 0.001 | 0.984 | network improved\n",
      "fold 4 | epoch 101 | 0.004 | 0.001 | 0.983\n",
      "fold 4 | epoch 102 | 0.004 | 0.001 | 0.984\n",
      "fold 4 | epoch 103 | 0.004 | 0.001 | 0.983\n",
      "fold 4 | epoch 104 | 0.004 | 0.001 | 0.984\n",
      "fold 4 | epoch 105 | 0.004 | 0.001 | 0.983\n",
      "fold 4 | epoch 106 | 0.004 | 0.001 | 0.984\n",
      "fold 4 | epoch 107 | 0.004 | 0.001 | 0.984\n",
      "fold 4 | epoch 108 | 0.004 | 0.001 | 0.985\n",
      "fold 4 | epoch 109 | 0.004 | 0.001 | 0.982\n",
      "fold 4 | epoch 110 | 0.004 | 0.000 | 0.985 | network improved\n",
      "fold 4 | epoch 111 | 0.004 | 0.001 | 0.984\n",
      "fold 4 | epoch 112 | 0.004 | 0.001 | 0.983\n",
      "fold 4 | epoch 113 | 0.004 | 0.001 | 0.983\n",
      "fold 4 | epoch 114 | 0.004 | 0.000 | 0.984 | network improved\n",
      "fold 4 | epoch 115 | 0.004 | 0.001 | 0.984\n",
      "fold 4 | epoch 116 | 0.004 | 0.001 | 0.983\n",
      "fold 4 | epoch 117 | 0.004 | 0.001 | 0.983\n",
      "fold 4 | epoch 118 | 0.004 | 0.001 | 0.984\n",
      "fold 4 | epoch 119 | 0.004 | 0.001 | 0.983\n",
      "fold 4 | epoch 120 | 0.003 | 0.001 | 0.983\n",
      "fold 4 | epoch 121 | 0.004 | 0.000 | 0.984 | network improved\n",
      "fold 4 | epoch 122 | 0.004 | 0.000 | 0.985\n",
      "fold 4 | epoch 123 | 0.003 | 0.000 | 0.984\n",
      "fold 4 | epoch 124 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 125 | 0.003 | 0.001 | 0.985\n",
      "fold 4 | epoch 126 | 0.004 | 0.001 | 0.984\n",
      "fold 4 | epoch 127 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 128 | 0.003 | 0.001 | 0.984\n",
      "fold 4 | epoch 129 | 0.003 | 0.001 | 0.984\n",
      "fold 4 | epoch 130 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 131 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 132 | 0.003 | 0.001 | 0.984\n",
      "fold 4 | epoch 133 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 134 | 0.003 | 0.000 | 0.982\n",
      "fold 4 | epoch 135 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 136 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 137 | 0.003 | 0.000 | 0.985 | network improved\n",
      "fold 4 | epoch 138 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 139 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 140 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 141 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 142 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 143 | 0.003 | 0.000 | 0.984\n",
      "fold 4 | epoch 144 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 145 | 0.003 | 0.000 | 0.984\n",
      "fold 4 | epoch 146 | 0.003 | 0.001 | 0.984\n",
      "fold 4 | epoch 147 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 148 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 149 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 150 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 151 | 0.003 | 0.000 | 0.985 | network improved\n",
      "fold 4 | epoch 152 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 153 | 0.003 | 0.001 | 0.985\n",
      "fold 4 | epoch 154 | 0.003 | 0.001 | 0.984\n",
      "fold 4 | epoch 155 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 156 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 157 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 158 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 159 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 160 | 0.003 | 0.001 | 0.985\n",
      "fold 4 | epoch 161 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 162 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 163 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 164 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 165 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 166 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 167 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 168 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 169 | 0.003 | 0.000 | 0.987 | network improved\n",
      "fold 4 | epoch 170 | 0.003 | 0.000 | 0.986 | network improved\n",
      "fold 4 | epoch 171 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 172 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 173 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 174 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 175 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 176 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 177 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 178 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 179 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 180 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 181 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 182 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 183 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 184 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 185 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 186 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 187 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 188 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 189 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 190 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 191 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 192 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 193 | 0.003 | 0.000 | 0.989 | network improved\n",
      "fold 4 | epoch 194 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 195 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 196 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 197 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 198 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 199 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 200 | 0.003 | 0.000 | 0.985\n",
      "fold 4 | epoch 201 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 202 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 203 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 204 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 205 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 206 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 207 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 208 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 209 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 210 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 211 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 212 | 0.003 | 0.000 | 0.989 | network improved\n",
      "fold 4 | epoch 213 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 214 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 215 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 216 | 0.003 | 0.000 | 0.989\n",
      "fold 4 | epoch 217 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 218 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 219 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 220 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 221 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 222 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 223 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 224 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 225 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 226 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 227 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 228 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 229 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 230 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 231 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 232 | 0.002 | 0.000 | 0.987\n",
      "fold 4 | epoch 233 | 0.003 | 0.000 | 0.989\n",
      "fold 4 | epoch 234 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 235 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 236 | 0.002 | 0.000 | 0.988\n",
      "fold 4 | epoch 237 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 238 | 0.003 | 0.000 | 0.986\n",
      "fold 4 | epoch 239 | 0.002 | 0.000 | 0.989 | network improved\n",
      "fold 4 | epoch 240 | 0.002 | 0.000 | 0.989\n",
      "fold 4 | epoch 241 | 0.002 | 0.000 | 0.989\n",
      "fold 4 | epoch 242 | 0.003 | 0.000 | 0.989\n",
      "fold 4 | epoch 243 | 0.003 | 0.000 | 0.988\n",
      "fold 4 | epoch 244 | 0.003 | 0.000 | 0.987\n",
      "fold 4 | epoch 245 | 0.002 | 0.000 | 0.988\n",
      "fold 4 | epoch 246 | 0.003 | 0.000 | 0.989\n",
      "fold 4 | epoch 247 | 0.003 | 0.000 | 0.989\n",
      "fold 4 | epoch 248 | 0.002 | 0.000 | 0.987\n",
      "fold 4 | epoch 249 | 0.002 | 0.000 | 0.989\n",
      "fold 4 | epoch 250 | 0.002 | 0.000 | 0.988\n",
      "fold 5 | epoch 1 | 0.087 | 0.015 | 0.561 | network improved\n",
      "fold 5 | epoch 2 | 0.061 | 0.010 | 0.758 | network improved\n",
      "fold 5 | epoch 3 | 0.043 | 0.007 | 0.817 | network improved\n",
      "fold 5 | epoch 4 | 0.034 | 0.005 | 0.857 | network improved\n",
      "fold 5 | epoch 5 | 0.028 | 0.004 | 0.880 | network improved\n",
      "fold 5 | epoch 6 | 0.024 | 0.004 | 0.894 | network improved\n",
      "fold 5 | epoch 7 | 0.021 | 0.003 | 0.906 | network improved\n",
      "fold 5 | epoch 8 | 0.019 | 0.003 | 0.919 | network improved\n",
      "fold 5 | epoch 9 | 0.017 | 0.003 | 0.929 | network improved\n",
      "fold 5 | epoch 10 | 0.016 | 0.002 | 0.927 | network improved\n",
      "fold 5 | epoch 11 | 0.015 | 0.002 | 0.936 | network improved\n",
      "fold 5 | epoch 12 | 0.014 | 0.002 | 0.940 | network improved\n",
      "fold 5 | epoch 13 | 0.013 | 0.002 | 0.946 | network improved\n",
      "fold 5 | epoch 14 | 0.012 | 0.002 | 0.947 | network improved\n",
      "fold 5 | epoch 15 | 0.012 | 0.002 | 0.948 | network improved\n",
      "fold 5 | epoch 16 | 0.011 | 0.002 | 0.955 | network improved\n",
      "fold 5 | epoch 17 | 0.011 | 0.002 | 0.952\n",
      "fold 5 | epoch 18 | 0.010 | 0.001 | 0.953 | network improved\n",
      "fold 5 | epoch 19 | 0.010 | 0.001 | 0.956 | network improved\n",
      "fold 5 | epoch 20 | 0.010 | 0.001 | 0.958 | network improved\n",
      "fold 5 | epoch 21 | 0.009 | 0.001 | 0.959 | network improved\n",
      "fold 5 | epoch 22 | 0.009 | 0.001 | 0.963 | network improved\n",
      "fold 5 | epoch 23 | 0.009 | 0.001 | 0.961\n",
      "fold 5 | epoch 24 | 0.009 | 0.001 | 0.964 | network improved\n",
      "fold 5 | epoch 25 | 0.009 | 0.001 | 0.963 | network improved\n",
      "fold 5 | epoch 26 | 0.008 | 0.001 | 0.963\n",
      "fold 5 | epoch 27 | 0.008 | 0.001 | 0.965 | network improved\n",
      "fold 5 | epoch 28 | 0.008 | 0.001 | 0.969\n",
      "fold 5 | epoch 29 | 0.008 | 0.001 | 0.965 | network improved\n",
      "fold 5 | epoch 30 | 0.007 | 0.001 | 0.965 | network improved\n",
      "fold 5 | epoch 31 | 0.007 | 0.001 | 0.969 | network improved\n",
      "fold 5 | epoch 32 | 0.007 | 0.001 | 0.971 | network improved\n",
      "fold 5 | epoch 33 | 0.007 | 0.001 | 0.969\n",
      "fold 5 | epoch 34 | 0.007 | 0.001 | 0.969\n",
      "fold 5 | epoch 35 | 0.007 | 0.001 | 0.970 | network improved\n",
      "fold 5 | epoch 36 | 0.007 | 0.001 | 0.971\n",
      "fold 5 | epoch 37 | 0.007 | 0.001 | 0.970\n",
      "fold 5 | epoch 38 | 0.007 | 0.001 | 0.971\n",
      "fold 5 | epoch 39 | 0.007 | 0.001 | 0.971 | network improved\n",
      "fold 5 | epoch 40 | 0.006 | 0.001 | 0.971\n",
      "fold 5 | epoch 41 | 0.006 | 0.001 | 0.975 | network improved\n",
      "fold 5 | epoch 42 | 0.006 | 0.001 | 0.973\n",
      "fold 5 | epoch 43 | 0.006 | 0.001 | 0.973\n",
      "fold 5 | epoch 44 | 0.006 | 0.001 | 0.973\n",
      "fold 5 | epoch 45 | 0.006 | 0.001 | 0.973\n",
      "fold 5 | epoch 46 | 0.006 | 0.001 | 0.975\n",
      "fold 5 | epoch 47 | 0.006 | 0.001 | 0.975 | network improved\n",
      "fold 5 | epoch 48 | 0.006 | 0.001 | 0.976\n",
      "fold 5 | epoch 49 | 0.006 | 0.001 | 0.974\n",
      "fold 5 | epoch 50 | 0.006 | 0.001 | 0.977\n",
      "fold 5 | epoch 51 | 0.006 | 0.001 | 0.974\n",
      "fold 5 | epoch 52 | 0.006 | 0.001 | 0.977\n",
      "fold 5 | epoch 53 | 0.006 | 0.001 | 0.977 | network improved\n",
      "fold 5 | epoch 54 | 0.006 | 0.001 | 0.976\n",
      "fold 5 | epoch 55 | 0.005 | 0.001 | 0.974\n",
      "fold 5 | epoch 56 | 0.005 | 0.001 | 0.976 | network improved\n",
      "fold 5 | epoch 57 | 0.005 | 0.001 | 0.979 | network improved\n",
      "fold 5 | epoch 58 | 0.005 | 0.001 | 0.975\n",
      "fold 5 | epoch 59 | 0.005 | 0.001 | 0.979 | network improved\n",
      "fold 5 | epoch 60 | 0.005 | 0.001 | 0.979\n",
      "fold 5 | epoch 61 | 0.005 | 0.001 | 0.979\n",
      "fold 5 | epoch 62 | 0.005 | 0.001 | 0.977\n",
      "fold 5 | epoch 63 | 0.005 | 0.001 | 0.976\n",
      "fold 5 | epoch 64 | 0.005 | 0.001 | 0.978\n",
      "fold 5 | epoch 65 | 0.005 | 0.001 | 0.979\n",
      "fold 5 | epoch 66 | 0.005 | 0.001 | 0.979 | network improved\n",
      "fold 5 | epoch 67 | 0.005 | 0.001 | 0.976\n",
      "fold 5 | epoch 68 | 0.005 | 0.001 | 0.978\n",
      "fold 5 | epoch 69 | 0.005 | 0.001 | 0.979\n",
      "fold 5 | epoch 70 | 0.005 | 0.001 | 0.979 | network improved\n",
      "fold 5 | epoch 71 | 0.005 | 0.001 | 0.979 | network improved\n",
      "fold 5 | epoch 72 | 0.005 | 0.001 | 0.979\n",
      "fold 5 | epoch 73 | 0.005 | 0.001 | 0.979\n",
      "fold 5 | epoch 74 | 0.004 | 0.001 | 0.978\n",
      "fold 5 | epoch 75 | 0.005 | 0.001 | 0.979\n",
      "fold 5 | epoch 76 | 0.005 | 0.001 | 0.980 | network improved\n",
      "fold 5 | epoch 77 | 0.004 | 0.001 | 0.982 | network improved\n",
      "fold 5 | epoch 78 | 0.004 | 0.001 | 0.978\n",
      "fold 5 | epoch 79 | 0.004 | 0.001 | 0.980\n",
      "fold 5 | epoch 80 | 0.004 | 0.001 | 0.977\n",
      "fold 5 | epoch 81 | 0.004 | 0.001 | 0.980 | network improved\n",
      "fold 5 | epoch 82 | 0.004 | 0.001 | 0.981\n",
      "fold 5 | epoch 83 | 0.004 | 0.001 | 0.979\n",
      "fold 5 | epoch 84 | 0.004 | 0.001 | 0.979\n",
      "fold 5 | epoch 85 | 0.004 | 0.001 | 0.980\n",
      "fold 5 | epoch 86 | 0.004 | 0.001 | 0.980\n",
      "fold 5 | epoch 87 | 0.004 | 0.001 | 0.979\n",
      "fold 5 | epoch 88 | 0.004 | 0.001 | 0.981\n",
      "fold 5 | epoch 89 | 0.004 | 0.001 | 0.982 | network improved\n",
      "fold 5 | epoch 90 | 0.004 | 0.001 | 0.981\n",
      "fold 5 | epoch 91 | 0.004 | 0.001 | 0.979\n",
      "fold 5 | epoch 92 | 0.004 | 0.001 | 0.980\n",
      "fold 5 | epoch 93 | 0.004 | 0.001 | 0.982\n",
      "fold 5 | epoch 94 | 0.004 | 0.001 | 0.983 | network improved\n",
      "fold 5 | epoch 95 | 0.004 | 0.001 | 0.980\n",
      "fold 5 | epoch 96 | 0.004 | 0.001 | 0.981\n",
      "fold 5 | epoch 97 | 0.004 | 0.001 | 0.983\n",
      "fold 5 | epoch 98 | 0.004 | 0.001 | 0.983\n",
      "fold 5 | epoch 99 | 0.004 | 0.001 | 0.983\n",
      "fold 5 | epoch 100 | 0.004 | 0.001 | 0.981\n",
      "fold 5 | epoch 101 | 0.004 | 0.001 | 0.983\n",
      "fold 5 | epoch 102 | 0.004 | 0.001 | 0.983 | network improved\n",
      "fold 5 | epoch 103 | 0.004 | 0.001 | 0.983\n",
      "fold 5 | epoch 104 | 0.004 | 0.001 | 0.984 | network improved\n",
      "fold 5 | epoch 105 | 0.004 | 0.001 | 0.982\n",
      "fold 5 | epoch 106 | 0.004 | 0.001 | 0.984\n",
      "fold 5 | epoch 107 | 0.004 | 0.001 | 0.983\n",
      "fold 5 | epoch 108 | 0.004 | 0.001 | 0.983\n",
      "fold 5 | epoch 109 | 0.004 | 0.001 | 0.982\n",
      "fold 5 | epoch 110 | 0.004 | 0.000 | 0.984 | network improved\n",
      "fold 5 | epoch 111 | 0.003 | 0.001 | 0.982\n",
      "fold 5 | epoch 112 | 0.004 | 0.001 | 0.983\n",
      "fold 5 | epoch 113 | 0.004 | 0.001 | 0.983\n",
      "fold 5 | epoch 114 | 0.004 | 0.001 | 0.983\n",
      "fold 5 | epoch 115 | 0.004 | 0.001 | 0.983\n",
      "fold 5 | epoch 116 | 0.004 | 0.001 | 0.982\n",
      "fold 5 | epoch 117 | 0.004 | 0.001 | 0.983\n",
      "fold 5 | epoch 118 | 0.004 | 0.001 | 0.982\n",
      "fold 5 | epoch 119 | 0.004 | 0.001 | 0.984\n",
      "fold 5 | epoch 120 | 0.004 | 0.001 | 0.984\n",
      "fold 5 | epoch 121 | 0.003 | 0.001 | 0.984\n",
      "fold 5 | epoch 122 | 0.003 | 0.000 | 0.984\n",
      "fold 5 | epoch 123 | 0.004 | 0.001 | 0.983\n",
      "fold 5 | epoch 124 | 0.003 | 0.000 | 0.984 | network improved\n",
      "fold 5 | epoch 125 | 0.003 | 0.001 | 0.983\n",
      "fold 5 | epoch 126 | 0.003 | 0.001 | 0.983\n",
      "fold 5 | epoch 127 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 128 | 0.003 | 0.001 | 0.983\n",
      "fold 5 | epoch 129 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 130 | 0.003 | 0.001 | 0.984\n",
      "fold 5 | epoch 131 | 0.004 | 0.000 | 0.986\n",
      "fold 5 | epoch 132 | 0.003 | 0.000 | 0.984 | network improved\n",
      "fold 5 | epoch 133 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 134 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 135 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 136 | 0.003 | 0.000 | 0.984\n",
      "fold 5 | epoch 137 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 138 | 0.003 | 0.000 | 0.985 | network improved\n",
      "fold 5 | epoch 139 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 140 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 141 | 0.003 | 0.000 | 0.984\n",
      "fold 5 | epoch 142 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 143 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 144 | 0.003 | 0.000 | 0.985 | network improved\n",
      "fold 5 | epoch 145 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 146 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 147 | 0.003 | 0.000 | 0.984\n",
      "fold 5 | epoch 148 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 149 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 150 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 151 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 152 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 153 | 0.003 | 0.000 | 0.988 | network improved\n",
      "fold 5 | epoch 154 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 155 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 156 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 157 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 158 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 159 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 160 | 0.003 | 0.000 | 0.984\n",
      "fold 5 | epoch 161 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 162 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 163 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 164 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 165 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 166 | 0.003 | 0.000 | 0.987 | network improved\n",
      "fold 5 | epoch 167 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 168 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 169 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 170 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 171 | 0.003 | 0.000 | 0.984\n",
      "fold 5 | epoch 172 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 173 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 174 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 175 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 176 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 177 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 178 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 179 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 180 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 181 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 182 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 183 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 184 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 185 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 186 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 187 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 188 | 0.003 | 0.000 | 0.986 | network improved\n",
      "fold 5 | epoch 189 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 190 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 191 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 192 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 193 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 194 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 195 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 196 | 0.003 | 0.000 | 0.985\n",
      "fold 5 | epoch 197 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 198 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 199 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 200 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 201 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 202 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 203 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 204 | 0.003 | 0.000 | 0.988 | network improved\n",
      "fold 5 | epoch 205 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 206 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 207 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 208 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 209 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 210 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 211 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 212 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 213 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 214 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 215 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 216 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 217 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 218 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 219 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 220 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 221 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 222 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 223 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 224 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 225 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 226 | 0.003 | 0.000 | 0.989\n",
      "fold 5 | epoch 227 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 228 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 229 | 0.003 | 0.000 | 0.986\n",
      "fold 5 | epoch 230 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 231 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 232 | 0.002 | 0.000 | 0.988\n",
      "fold 5 | epoch 233 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 234 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 235 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 236 | 0.002 | 0.000 | 0.988\n",
      "fold 5 | epoch 237 | 0.002 | 0.000 | 0.989\n",
      "fold 5 | epoch 238 | 0.003 | 0.000 | 0.988 | network improved\n",
      "fold 5 | epoch 239 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 240 | 0.002 | 0.000 | 0.989\n",
      "fold 5 | epoch 241 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 242 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 243 | 0.002 | 0.000 | 0.990\n",
      "fold 5 | epoch 244 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 245 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 246 | 0.002 | 0.000 | 0.989\n",
      "fold 5 | epoch 247 | 0.003 | 0.000 | 0.987\n",
      "fold 5 | epoch 248 | 0.003 | 0.000 | 0.988\n",
      "fold 5 | epoch 249 | 0.002 | 0.000 | 0.988\n",
      "fold 5 | epoch 250 | 0.002 | 0.000 | 0.987\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "device = torch.device('mps')\n",
    "\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "epochs = 250\n",
    "running_losses_list, val_losses_list, val_accuracies_list = [], [], []\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kf.split(train_data)):\n",
    "    train_sampler = SubsetRandomSampler(train_ids)\n",
    "    val_sampler = SubsetRandomSampler(val_ids)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "    val_loader = DataLoader(train_data, batch_size=batch_size, sampler=val_sampler)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    running_loss_min = np.inf\n",
    "    val_loss_min = np.inf\n",
    "\n",
    "    running_losses, val_losses, val_accuracies = [], [], []\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        val_accuracy = correct / total\n",
    "        \n",
    "        running_losses.append(running_loss/total)\n",
    "        val_losses.append(val_loss/total)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        network_learned = (running_loss < running_loss_min) & (val_loss < val_loss_min)\n",
    "        if network_learned:\n",
    "            running_loss_min = running_loss\n",
    "            val_loss_min = val_loss\n",
    "            torch.save(model.state_dict(), 'model_mnist_' + str(fold+1) + '.pt')\n",
    "            print(f'fold {fold+1} | epoch {e+1} | {running_loss/total:.3f} | {val_loss/total:.3f} | {val_accuracy:.3f} | network improved')\n",
    "        else:\n",
    "            print(f'fold {fold+1} | epoch {e+1} | {running_loss/total:.3f} | {val_loss/total:.3f} | {val_accuracy:.3f}')\n",
    "\n",
    "    running_losses_list.append(running_losses)\n",
    "    val_losses_list.append(val_losses)\n",
    "    val_accuracies_list.append(val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5873d2f-26c2-4210-9214-5a3335c77aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(0, 5):\n",
    "    model = Net().to(device)\n",
    "    model.load_state_dict(torch.load('model_mnist_' + str(i+1) + '.pt', weights_only=False))\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=len(test_data), shuffle=False)\n",
    "\n",
    "pred = np.zeros(280000).reshape(28000, 10)\n",
    "with torch.no_grad():\n",
    "    for model in models:\n",
    "        for images in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            pred += 0.2 * outputs.cpu().numpy()\n",
    "\n",
    "predictions = pd.DataFrame(np.argmax(pred, axis=1), columns=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "436c53c6-6b43-4ded-9357-ee77a13b474e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label\n",
       "0          2\n",
       "1          0\n",
       "2          9\n",
       "3          0\n",
       "4          3\n",
       "...      ...\n",
       "27995      9\n",
       "27996      7\n",
       "27997      3\n",
       "27998      9\n",
       "27999      2\n",
       "\n",
       "[28000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d952427-b886-4bc5-a31d-d1a54f9af9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.index += 1\n",
    "predictions.index.name = 'ImageId'\n",
    "predictions.to_csv('submission_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0171b7-da3f-432d-8f34-8a5c135d1cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
